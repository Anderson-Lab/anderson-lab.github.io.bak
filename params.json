{"name":"Anderson Data Science Research Lab","tagline":"Machine Learning + Big Data + Data Science","body":"<i>If you don’t work on important problems, it’s not likely that you’ll do important work.</i> — Richard Hamming\r\n\r\n<i>Geeks stay up all night disassembling the world so they can put it back together with new features. They tinker and fix things that aren't broken. Geeks abandon the world around them because they're busing soldering together a new one. They obsess and, in many cases, they suffer.</i> — Matthew Inman\r\n\r\n# <a href=\"http://anderson-lab.github.io/\">The Lab</a>\r\n\r\n<p align=\"justify\">\r\n<a href=\"http://anderson-lab.github.io/\"><img src=\"http://freyja.cs.cofc.edu/Paul-labs-logo.png\" alt=\"Data Science Research Lab\" height=\"100\" align=\"right\"  hspace=\"10px\"/></a>\r\nThe Anderson Data Science Research Lab specializes in applying data mining, machine learning, and artificial intelligence to the fields of bioinformatics, genomics, and metabolomics. We develop algorithms and software to tackle some of the most challenging and interesting data intensive problems in the life sciences. Our research interests include data science, big data, pattern analysis in high-dimensional data sets, evolutionary computation and optimization, machine learning, computational genomics, cloud computing, computational metabolomics, and eScience. We currently have multidisciplinary projects underway in metabolomics, human cognition, toxicology, marine biology, medical genomics, biomedical informatics, and marine genomics.\r\n</p>\r\n\r\n# Research Groups\r\n## Data Science Foundations\r\nThe Data Science Foundations Group researches fundamental problems and solutions for the general field of data science, specializing in machine learning, big data, pattern analysis in high-dimensional data sets, and deep learning. Two example ongoing projects are research into kernel approximation methods for supervised learning and distributed deep learning algorithms on Apache Spark.\r\n\r\n### Distributed Deep Learning with Apache Spark\r\nIt has been shown that training large models with deep learning techniques increases their performance and classification power. A group at Google pioneered two such algorithms: Downpour SGD, an asynchronous stochastic gradient descent method, and Sandblaster, a framework which is built upon the idea of distributed batch optimization. These algorithms improve training by having many model replicas while having a shared set of parameters hosted on an independent server. Additionally, each model replica is a Distbelief model, a set of machines that communicate in order to build even larger networks for classification. However, this framework has not been made available to the public and relies on the implementation of consistent and rapid communication and message-passing. There is a rise in the popularity of frameworks that simplify these communication mechanisms, most notably Apache Spark. Spark’s popularity is partially attributed to its seamless integration with other cluster frameworks, such as Hadoop, as well as its capability to act as a stand-alone cluster.  Additionally, Spark has been shown to adapt well to the parallelization of popular machine learning algorithms, which is shown through Spark’s native machine learning library. We have implemented the original system and set of algorithms in Python using XML remote procedure calls as the method of communication. We plan to compare the efficiency and ease-of-use of this system to a Spark implementation of the framework.  \r\n\r\n### Fast Food Elastic Net\r\nBowick et al extended the application of fast food (FF) kernel approximations to neural networks by creating a multilayer perceptron (MLP) which learned nonlinear FF feature transforms at each layer, providing an additional nonlinearity application in the MLP algorithm. They compared the performance of FF optimized NNs (FONNs), which optimize the FF parameters alongside the weight and bias parameters in the MLP training algorithm (such as backpropagation), against that of FF randomized NNs (FRNNs), which randomly generate the FF parameters without optimization, saving computational resources during training. Dai et al extended the model that Le and Smola and Rahimi and Recht constructed on top of NNs (creating a doubly non-linear NN) by creating the Doubly Stochastic Kernel Machine. We propose to apply FF to various machine learning algorithms which are traditionally non-kernel based. We compare the performance, on a large n dataset, of a support vector machine equipped with elastic net (SVEN) (which is computationally impractical on such datasets) against that of a novel model composed of the input patterns being transformed by the nonlinear FF feature transforms before being passed through an elastic net.\r\n\r\n## Bioinformatics\r\n\r\n## Biomedical Informatics\r\n\r\n## Computational Metabolomics\r\n\r\n## C2G2\r\nThe goal of the Charleston Computational Genomics Group or C2G2 is to develop computational techniques, methodology, and infrastructure to efficiently analyze genomic and bioinformatic data with the express purpose of training undergraduate students to excel as scientists, software engineers, computer scientists, and bioinformaticians. Our objectives are to (1) build cyberinfrastructure for Charleston area genomics and bioinformatics projects,\r\n(2) develop novel software and algorithms for data mining, data acquisition, data storage, data management, data integration, data mining, data visualization, (3) train students in the genomic and bioinformatic sciences to be utilized at local and foreign institutions, and (4) collaborate with Charleston area scientists studying genomic medicine, genome theory, gene expression, marine genomics, etc.\r\n\r\n### Investigators\r\nThe PI for the project is Paul Anderson of the College of Charleston Computer Science Department. Co-PIs are Andrew Shedlock of the College of Charleston Biology Department and Dennis Watson of MUSC's Department of Pathology and Laboratory Medicine. Other members of the team are Bob Wilson, Director of the Genomics Core at MUSC. Alumni of the group are Jeremy Morgan, Connor Stanley, Matt Paul, and Tori McCaffrey.\r\n\r\n### Education\r\nIn addition to this research program, we have several ongoing academic initiatives to prepare and expose students to this exciting new field. Dr. Paul Anderson is the Director of the Data Science Program at the College of Charleston and routinely teaches Data Science courses. Dr. Andy Shedlock teaches a Vertebrate Genomics course for graduate and advanced undergraduate students, which includes a intensive laboratory experience (co-taught with Dr. Paul Anderson). In addition to this formal coursework, we are consistently meeting to discuss ongoing research projects and encourage interested students to contact one of the PIs.\r\n\r\n### Big Data Infrastructure\r\nThe C2G2 group currently maintains two compute clusters configured and optimized for computational genomics. The original commodity-based cluster is comprised of 4 nodes, with a total of 32 cores, 32 GB RAM per node, and 12 TB of raw storage. The recently awarded GEAR: CI grant has resulted in the purchase of a new high performance cluster comprised of 10 nodes, with more than 200 cores, 200+ TB of raw storage, 64 - 400 GB of RAM per node, and 4 Gb network connections. The C2G2 group also maintains cloud storage resources for the transfer, management, and organization of scientific data sets.\r\n\r\n## Primary Investigator\r\nDr. Paul Anderson graduated in 2004 from Wright State University with a B.S. degree in Computer Engineering. He received his masters in Computer Science in 2006 and his Ph.D. in Computer Science & Engineering in June 2010. After graduation, Dr. Anderson was awarded a Consortium of Universities Research Fellowship to study as a Bioinformatics Research Scientist for the Air Force Research Laboratory (AFRL). Dr. Anderson has published 24+ peer-reviewed articles in the fields of genomics, computational intelligence, metabolomics, e-Science, bioinformatics, cloud computing, cancer informatics, and computer science and engineering education. At present, Paul is an assistant professor in the Computer Science Department at the College of Charleston. He is the director of the Data Science Program, the first such undergraduate program in the country. Dr. Anderson is the director of several specialized and complementary research groups: Charleston Computational Genomics Group (C2G2), Computational Metabolomics Group (CMG), Bioinformatics Research Group (BiRG), and the Data Science Research Group (DSRG). His research labs at the College of Charleston specialize in applying data mining, machine learning, and artificial intelligence to the fields of bioinformatics, genomics, cancer informatics, and metabolomics. His lab develops algorithms and software to tackle some of the most challenging and interesting data intensive problems in the life sciences. Dr. Anderson’s research interests include data science, big data, pattern analysis in high-dimensionality data sets, evolutionary computation and optimization, machine learning, computational genomics, cloud computing, computational metabolomics, and eScience. He currently has multidisciplinary projects underway in metabolomics, human cognition and fatigue, toxicology, marine biology, cancer informatics, and medical and marine genomics. Dr. Anderson is also the primary investigator for new Omics NSF Research Experience for Undergraduates at the College of Charleston (<a href=\"http://omics.cofc.edu\">http://omics.cofc.edu</a>).","google":"","note":"Don't delete this file! It's used internally to help with page regeneration."}